{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net for combined Copy Number Variation and RNAseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a.su/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "working_directory = '/Users/a.su/Documents/MultiClassCancer_RNAseq_CNV_lncRNA/'\n",
    "\n",
    "#Import Data\n",
    "y = pd.read_table(working_directory + 'CancerTypes_y_BinaryClass.txt', sep = '\\t', header = None)\n",
    "x_cnv = pd.read_table(working_directory + 'CNV_processed_multiClass.txt', sep = '\\t', header = 0)\n",
    "x_rna = pd.read_table(working_directory + 'RNAseq_processed_multiClass.txt', sep = '\\t', header = 0)\n",
    "x_lnc = pd.read_table(working_directory + 'lncRNA_processed_multiClass.txt', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cnv shape is:(668, 26374)  x_rna shape is:(668, 26094)  x_lnc shape is:(668, 21770)\n",
      "y shape is: (668, 1)\n"
     ]
    }
   ],
   "source": [
    "# Remove GeneID Column\n",
    "x_cnv = x_cnv.drop('GeneID', axis = 1)\n",
    "x_rna = x_rna.drop('GeneID', axis = 1)\n",
    "x_lnc = x_lnc.drop('GeneID', axis = 1)\n",
    "\n",
    "# Transpose\n",
    "x_cnv = x_cnv.transpose()\n",
    "x_rna = x_rna.transpose()\n",
    "x_lnc = x_lnc.transpose()\n",
    "print('x_cnv shape is:{0}  x_rna shape is:{1}  x_lnc shape is:{2}'.format(x_cnv.shape, x_rna.shape, x_lnc.shape))\n",
    "print('y shape is:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 Columns from x_cnv\n",
      "Dropped 0 Columns from x_rna\n",
      "Dropped 0 Columns from x_lnc\n"
     ]
    }
   ],
   "source": [
    "drop_threshold = 0.5*len(x_cnv.index)\n",
    "\n",
    "#DropNa from columns with at least 50% NaN\n",
    "x_cnv_dropped = x_cnv.dropna(thresh = drop_threshold)\n",
    "x_rna_dropped = x_rna.dropna(thresh = drop_threshold)\n",
    "x_lnc_dropped = x_lnc.dropna(thresh = drop_threshold)\n",
    "\n",
    "#Columns dropped\n",
    "def print_dropped_columns(df, df_dropped, df_name):\n",
    "    print('Dropped {0} Columns from {1}'.format(len(df.columns) - len(df_dropped.columns), df_name))\n",
    "\n",
    "print_dropped_columns(x_cnv, x_cnv_dropped, 'x_cnv')\n",
    "print_dropped_columns(x_rna, x_rna_dropped, 'x_rna')\n",
    "print_dropped_columns(x_lnc, x_lnc_dropped, 'x_lnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Impute \n",
    "impute_median = SimpleImputer(strategy = 'median')\n",
    "x_cnv_imputed = pd.DataFrame(impute_median.fit_transform(x_cnv_dropped))\n",
    "x_rna_imputed = pd.DataFrame(impute_median.fit_transform(x_rna_dropped))\n",
    "x_lnc_imputed = pd.DataFrame(impute_median.fit_transform(x_lnc_dropped))\n",
    "\n",
    "#Check for NaN values\n",
    "print(np.isnan(x_cnv_imputed).all().any())\n",
    "print(np.isnan(x_rna_imputed).all().any())\n",
    "print(np.isnan(x_lnc_imputed).all().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV: 0  RNA: 111  lnc: 374\n"
     ]
    }
   ],
   "source": [
    "def count_all_zeros (df, _axis_ = 0):\n",
    "    return len(df.columns) - np.count_nonzero(df.sum(axis = _axis_), axis = _axis_)\n",
    "\n",
    "#Count number of columns with all zeros\n",
    "print('CNV: {0}  RNA: {1}  lnc: {2}'.format(count_all_zeros(x_cnv_imputed, 0), count_all_zeros(x_rna_imputed, 0), count_all_zeros(x_lnc_imputed, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 Columns from x_cnv_imputed\n",
      "Dropped 111 Columns from x_rna_imputed\n",
      "Dropped 374 Columns from x_lnc_imputed\n"
     ]
    }
   ],
   "source": [
    "#Delete columns with all zeros\n",
    "x_cnv_nozero = x_cnv_imputed.loc[:, (x_cnv_imputed != 0).any(axis = 0)]\n",
    "x_rna_nozero = x_rna_imputed.loc[:, (x_rna_imputed != 0).any(axis = 0)]\n",
    "x_lnc_nozero = x_lnc_imputed.loc[:, (x_lnc_imputed != 0).any(axis = 0)]\n",
    "\n",
    "#Count number of column deletions\n",
    "print_dropped_columns(x_cnv_imputed, x_cnv_nozero, 'x_cnv_imputed')\n",
    "print_dropped_columns(x_rna_imputed, x_rna_nozero, 'x_rna_imputed')\n",
    "print_dropped_columns(x_lnc_imputed, x_lnc_nozero, 'x_lnc_imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV: 0  RNA: 0  lnc: 0\n"
     ]
    }
   ],
   "source": [
    "#Count number of columns with all zeros\n",
    "print('CNV: {0}  RNA: {1}  lnc: {2}'.format(count_all_zeros(x_cnv_nozero, 0), count_all_zeros(x_rna_nozero, 0), count_all_zeros(x_lnc_nozero, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "zscore = lambda x: (x-x.mean())/ x.std()\n",
    "\n",
    "x_rna_processed, x_cnv_processed, x_lnc_processed = x_rna_nozero.transform(zscore), x_cnv_nozero.transform(zscore), x_lnc_nozero.transform(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14672</th>\n",
       "      <th>18052</th>\n",
       "      <th>20580</th>\n",
       "      <th>18549</th>\n",
       "      <th>2719</th>\n",
       "      <th>18332</th>\n",
       "      <th>9091</th>\n",
       "      <th>4592</th>\n",
       "      <th>12136</th>\n",
       "      <th>18279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.020474e-16</td>\n",
       "      <td>2.227094e-16</td>\n",
       "      <td>7.813111e-16</td>\n",
       "      <td>4.175801e-17</td>\n",
       "      <td>-3.417094e-16</td>\n",
       "      <td>1.573259e-15</td>\n",
       "      <td>-4.356130e-16</td>\n",
       "      <td>3.639803e-16</td>\n",
       "      <td>-2.451466e-17</td>\n",
       "      <td>-1.349802e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.201311e+00</td>\n",
       "      <td>-3.993460e-01</td>\n",
       "      <td>-1.771311e+00</td>\n",
       "      <td>-2.388145e-01</td>\n",
       "      <td>-8.691430e-02</td>\n",
       "      <td>-1.563346e+00</td>\n",
       "      <td>-1.092004e+00</td>\n",
       "      <td>-2.737612e-01</td>\n",
       "      <td>-3.173229e-01</td>\n",
       "      <td>-1.610544e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.329339e-01</td>\n",
       "      <td>-3.993460e-01</td>\n",
       "      <td>-5.956098e-01</td>\n",
       "      <td>-2.388145e-01</td>\n",
       "      <td>-8.691430e-02</td>\n",
       "      <td>-6.293582e-01</td>\n",
       "      <td>-5.589228e-01</td>\n",
       "      <td>-2.737612e-01</td>\n",
       "      <td>-3.173229e-01</td>\n",
       "      <td>-6.851349e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.384287e-01</td>\n",
       "      <td>-3.993460e-01</td>\n",
       "      <td>-1.781259e-01</td>\n",
       "      <td>-2.183968e-01</td>\n",
       "      <td>-8.691430e-02</td>\n",
       "      <td>-2.080033e-01</td>\n",
       "      <td>-2.098671e-01</td>\n",
       "      <td>-2.704880e-01</td>\n",
       "      <td>-2.789276e-01</td>\n",
       "      <td>-1.818797e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.419763e-01</td>\n",
       "      <td>-2.656665e-01</td>\n",
       "      <td>3.451873e-01</td>\n",
       "      <td>-1.292290e-01</td>\n",
       "      <td>-8.691430e-02</td>\n",
       "      <td>3.658430e-01</td>\n",
       "      <td>2.618646e-01</td>\n",
       "      <td>-6.177871e-02</td>\n",
       "      <td>-1.052099e-01</td>\n",
       "      <td>4.084009e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.670687e+00</td>\n",
       "      <td>7.892324e+00</td>\n",
       "      <td>1.290248e+01</td>\n",
       "      <td>1.951892e+01</td>\n",
       "      <td>1.873396e+01</td>\n",
       "      <td>1.096673e+01</td>\n",
       "      <td>1.193053e+01</td>\n",
       "      <td>1.390330e+01</td>\n",
       "      <td>1.635716e+01</td>\n",
       "      <td>7.075243e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              14672         18052         20580         18549         2719   \\\n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02   \n",
       "mean   1.020474e-16  2.227094e-16  7.813111e-16  4.175801e-17 -3.417094e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.201311e+00 -3.993460e-01 -1.771311e+00 -2.388145e-01 -8.691430e-02   \n",
       "25%   -7.329339e-01 -3.993460e-01 -5.956098e-01 -2.388145e-01 -8.691430e-02   \n",
       "50%   -2.384287e-01 -3.993460e-01 -1.781259e-01 -2.183968e-01 -8.691430e-02   \n",
       "75%    4.419763e-01 -2.656665e-01  3.451873e-01 -1.292290e-01 -8.691430e-02   \n",
       "max    4.670687e+00  7.892324e+00  1.290248e+01  1.951892e+01  1.873396e+01   \n",
       "\n",
       "              18332         9091          4592          12136         18279  \n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  \n",
       "mean   1.573259e-15 -4.356130e-16  3.639803e-16 -2.451466e-17 -1.349802e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -1.563346e+00 -1.092004e+00 -2.737612e-01 -3.173229e-01 -1.610544e+00  \n",
       "25%   -6.293582e-01 -5.589228e-01 -2.737612e-01 -3.173229e-01 -6.851349e-01  \n",
       "50%   -2.080033e-01 -2.098671e-01 -2.704880e-01 -2.789276e-01 -1.818797e-01  \n",
       "75%    3.658430e-01  2.618646e-01 -6.177871e-02 -1.052099e-01  4.084009e-01  \n",
       "max    1.096673e+01  1.193053e+01  1.390330e+01  1.635716e+01  7.075243e+00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualise\n",
    "x_rna_processed[np.random.choice(x_rna_processed.columns.values, size = 10, replace = False)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21076</th>\n",
       "      <th>6210</th>\n",
       "      <th>20854</th>\n",
       "      <th>4698</th>\n",
       "      <th>1768</th>\n",
       "      <th>21843</th>\n",
       "      <th>24096</th>\n",
       "      <th>2005</th>\n",
       "      <th>21675</th>\n",
       "      <th>24633</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.397149e-16</td>\n",
       "      <td>-4.219845e-16</td>\n",
       "      <td>-5.337547e-16</td>\n",
       "      <td>-1.089448e-15</td>\n",
       "      <td>3.806004e-17</td>\n",
       "      <td>-3.643127e-16</td>\n",
       "      <td>-3.897415e-16</td>\n",
       "      <td>-3.084692e-16</td>\n",
       "      <td>-1.062025e-16</td>\n",
       "      <td>3.689663e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.381398e+00</td>\n",
       "      <td>-3.090586e+00</td>\n",
       "      <td>-1.986745e+00</td>\n",
       "      <td>-3.135119e+00</td>\n",
       "      <td>-2.604649e+00</td>\n",
       "      <td>-3.044525e+00</td>\n",
       "      <td>-3.058483e+00</td>\n",
       "      <td>-3.393235e+00</td>\n",
       "      <td>-2.028328e+00</td>\n",
       "      <td>-2.295783e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.243816e-01</td>\n",
       "      <td>-6.339691e-01</td>\n",
       "      <td>-6.182360e-01</td>\n",
       "      <td>-6.784284e-01</td>\n",
       "      <td>-6.442062e-01</td>\n",
       "      <td>-6.757195e-01</td>\n",
       "      <td>-7.266223e-01</td>\n",
       "      <td>-6.095486e-01</td>\n",
       "      <td>-6.352684e-01</td>\n",
       "      <td>-6.346993e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.182303e-01</td>\n",
       "      <td>8.924184e-02</td>\n",
       "      <td>-1.392608e-01</td>\n",
       "      <td>1.646195e-01</td>\n",
       "      <td>-1.585160e-01</td>\n",
       "      <td>7.224287e-02</td>\n",
       "      <td>-5.450844e-02</td>\n",
       "      <td>-1.257937e-01</td>\n",
       "      <td>3.055787e-03</td>\n",
       "      <td>-7.486381e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.092519e-01</td>\n",
       "      <td>5.891467e-01</td>\n",
       "      <td>4.776140e-01</td>\n",
       "      <td>6.441616e-01</td>\n",
       "      <td>5.401521e-01</td>\n",
       "      <td>5.620206e-01</td>\n",
       "      <td>6.533444e-01</td>\n",
       "      <td>5.894343e-01</td>\n",
       "      <td>4.615357e-01</td>\n",
       "      <td>3.985932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.463698e+00</td>\n",
       "      <td>4.177867e+00</td>\n",
       "      <td>8.399086e+00</td>\n",
       "      <td>2.828113e+00</td>\n",
       "      <td>4.123763e+00</td>\n",
       "      <td>4.148804e+00</td>\n",
       "      <td>4.713583e+00</td>\n",
       "      <td>3.407939e+00</td>\n",
       "      <td>7.191099e+00</td>\n",
       "      <td>6.717284e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              21076         6210          20854         4698          1768   \\\n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02   \n",
       "mean  -3.397149e-16 -4.219845e-16 -5.337547e-16 -1.089448e-15  3.806004e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.381398e+00 -3.090586e+00 -1.986745e+00 -3.135119e+00 -2.604649e+00   \n",
       "25%   -6.243816e-01 -6.339691e-01 -6.182360e-01 -6.784284e-01 -6.442062e-01   \n",
       "50%   -1.182303e-01  8.924184e-02 -1.392608e-01  1.646195e-01 -1.585160e-01   \n",
       "75%    5.092519e-01  5.891467e-01  4.776140e-01  6.441616e-01  5.401521e-01   \n",
       "max    4.463698e+00  4.177867e+00  8.399086e+00  2.828113e+00  4.123763e+00   \n",
       "\n",
       "              21843         24096         2005          21675         24633  \n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  \n",
       "mean  -3.643127e-16 -3.897415e-16 -3.084692e-16 -1.062025e-16  3.689663e-17  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.044525e+00 -3.058483e+00 -3.393235e+00 -2.028328e+00 -2.295783e+00  \n",
       "25%   -6.757195e-01 -7.266223e-01 -6.095486e-01 -6.352684e-01 -6.346993e-01  \n",
       "50%    7.224287e-02 -5.450844e-02 -1.257937e-01  3.055787e-03 -7.486381e-02  \n",
       "75%    5.620206e-01  6.533444e-01  5.894343e-01  4.615357e-01  3.985932e-01  \n",
       "max    4.148804e+00  4.713583e+00  3.407939e+00  7.191099e+00  6.717284e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cnv_processed[np.random.choice(x_cnv_processed.columns.values, size = 10, replace = False)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9170</th>\n",
       "      <th>16457</th>\n",
       "      <th>1703</th>\n",
       "      <th>33</th>\n",
       "      <th>14320</th>\n",
       "      <th>1991</th>\n",
       "      <th>6639</th>\n",
       "      <th>12017</th>\n",
       "      <th>5202</th>\n",
       "      <th>6811</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>6.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.989115e-16</td>\n",
       "      <td>-1.893030e-16</td>\n",
       "      <td>-8.442182e-16</td>\n",
       "      <td>4.783266e-16</td>\n",
       "      <td>8.569326e-16</td>\n",
       "      <td>6.245836e-16</td>\n",
       "      <td>2.660546e-15</td>\n",
       "      <td>-8.509494e-17</td>\n",
       "      <td>3.901570e-16</td>\n",
       "      <td>3.398812e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.940287e-02</td>\n",
       "      <td>-1.458500e-01</td>\n",
       "      <td>-1.468573e+00</td>\n",
       "      <td>-9.232185e-01</td>\n",
       "      <td>-9.084244e-01</td>\n",
       "      <td>-3.148980e-01</td>\n",
       "      <td>-2.023992e+00</td>\n",
       "      <td>-7.250077e-01</td>\n",
       "      <td>-6.568212e-01</td>\n",
       "      <td>-1.455076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.940287e-02</td>\n",
       "      <td>-1.458500e-01</td>\n",
       "      <td>-7.380860e-01</td>\n",
       "      <td>-6.525047e-01</td>\n",
       "      <td>-6.434925e-01</td>\n",
       "      <td>-3.148980e-01</td>\n",
       "      <td>-6.896770e-01</td>\n",
       "      <td>-5.909244e-01</td>\n",
       "      <td>-5.118673e-01</td>\n",
       "      <td>-1.455076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.711095e-02</td>\n",
       "      <td>-1.458500e-01</td>\n",
       "      <td>-2.059913e-01</td>\n",
       "      <td>-2.697507e-01</td>\n",
       "      <td>-3.296807e-01</td>\n",
       "      <td>-3.148980e-01</td>\n",
       "      <td>-1.145508e-01</td>\n",
       "      <td>-3.314364e-01</td>\n",
       "      <td>-2.730146e-01</td>\n",
       "      <td>-1.455076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.578878e-02</td>\n",
       "      <td>-1.106315e-01</td>\n",
       "      <td>4.755136e-01</td>\n",
       "      <td>2.764192e-01</td>\n",
       "      <td>2.638017e-01</td>\n",
       "      <td>-3.148980e-01</td>\n",
       "      <td>5.289162e-01</td>\n",
       "      <td>2.424804e-01</td>\n",
       "      <td>1.098308e-01</td>\n",
       "      <td>-1.455076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.917437e+01</td>\n",
       "      <td>2.083343e+01</td>\n",
       "      <td>6.293982e+00</td>\n",
       "      <td>7.454403e+00</td>\n",
       "      <td>6.899406e+00</td>\n",
       "      <td>1.290742e+01</td>\n",
       "      <td>4.383630e+00</td>\n",
       "      <td>1.013575e+01</td>\n",
       "      <td>1.044517e+01</td>\n",
       "      <td>2.029958e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              9170          16457         1703          33            14320  \\\n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02   \n",
       "mean   1.989115e-16 -1.893030e-16 -8.442182e-16  4.783266e-16  8.569326e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -9.940287e-02 -1.458500e-01 -1.468573e+00 -9.232185e-01 -9.084244e-01   \n",
       "25%   -9.940287e-02 -1.458500e-01 -7.380860e-01 -6.525047e-01 -6.434925e-01   \n",
       "50%   -9.711095e-02 -1.458500e-01 -2.059913e-01 -2.697507e-01 -3.296807e-01   \n",
       "75%   -8.578878e-02 -1.106315e-01  4.755136e-01  2.764192e-01  2.638017e-01   \n",
       "max    1.917437e+01  2.083343e+01  6.293982e+00  7.454403e+00  6.899406e+00   \n",
       "\n",
       "              1991          6639          12017         5202          6811   \n",
       "count  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  6.680000e+02  \n",
       "mean   6.245836e-16  2.660546e-15 -8.509494e-17  3.901570e-16  3.398812e-16  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.148980e-01 -2.023992e+00 -7.250077e-01 -6.568212e-01 -1.455076e-01  \n",
       "25%   -3.148980e-01 -6.896770e-01 -5.909244e-01 -5.118673e-01 -1.455076e-01  \n",
       "50%   -3.148980e-01 -1.145508e-01 -3.314364e-01 -2.730146e-01 -1.455076e-01  \n",
       "75%   -3.148980e-01  5.289162e-01  2.424804e-01  1.098308e-01 -1.455076e-01  \n",
       "max    1.290742e+01  4.383630e+00  1.013575e+01  1.044517e+01  2.029958e+01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lnc_processed[np.random.choice(x_lnc_processed.columns.values, size = 10, replace = False)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV: False  RNA: False  lnc: False\n"
     ]
    }
   ],
   "source": [
    "#Check for NaN values\n",
    "print('CNV: {0}  RNA: {1}  lnc: {2}'.format(\n",
    "    x_cnv_processed.isnull().any().any(), x_rna_processed.isnull().any().any(), x_lnc_processed.isnull().any().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x1a1ab6def0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reset Indexes for dataframes\n",
    "def reset_df_index(df):\n",
    "    df = df.reset_index(drop = True)\n",
    "map(reset_df_index, [x_cnv_processed, x_rna_processed, x_lnc_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cr shape is:(668, 52357)  x_cl shape is:(668, 47770)  x_rl shape is:(668, 47379)\n"
     ]
    }
   ],
   "source": [
    "#Combine data as pairs\n",
    "x_cr = pd.concat([x_cnv_processed, x_rna_processed], axis = 1)\n",
    "x_cl = pd.concat([x_cnv_processed, x_lnc_processed], axis = 1)\n",
    "x_rl = pd.concat([x_rna_processed, x_lnc_processed], axis = 1)\n",
    "\n",
    "print('x_cr shape is:{0}  x_cl shape is:{1}  x_rl shape is:{2}'.format(x_cr.shape, x_cl.shape, x_rl.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 73753)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine all data \n",
    "x_all = pd.concat([x_cnv_processed, x_rna_processed, x_lnc_processed], axis = 1)\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "x_combined_train, x_combined_test, y_combined_train, y_combined_test = train_test_split(\n",
    "    x_all, y.values.flatten(), test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best settings so far are:\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "Accuracy ~81.4%\n",
    "\n",
    "model.add(Dense(16, activation = 'tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation = 'tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "Accuracy ~82% with 150 epochs\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dense(16, activation = 'tanh'))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(16, activation = 'tanh'))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(32, activation = 'relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid', kernel_regularizer = regularizers.l1(0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "501/501 [==============================] - 1s 3ms/step - loss: 20.5489 - acc: 0.5569\n",
      "Epoch 2/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 7.4053 - acc: 0.6607\n",
      "Epoch 3/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 5.2345 - acc: 0.6347\n",
      "Epoch 4/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 3.6581 - acc: 0.5908\n",
      "Epoch 5/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.9450 - acc: 0.5908\n",
      "Epoch 6/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.5733 - acc: 0.5669\n",
      "Epoch 7/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.3645 - acc: 0.5709\n",
      "Epoch 8/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.2436 - acc: 0.5928\n",
      "Epoch 9/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.2119 - acc: 0.5988\n",
      "Epoch 10/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.2326 - acc: 0.5808\n",
      "Epoch 11/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1880 - acc: 0.5928\n",
      "Epoch 12/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1849 - acc: 0.6088\n",
      "Epoch 13/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1263 - acc: 0.6527\n",
      "Epoch 14/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1510 - acc: 0.6048\n",
      "Epoch 15/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1219 - acc: 0.6467\n",
      "Epoch 16/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1450 - acc: 0.6088\n",
      "Epoch 17/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1534 - acc: 0.6108\n",
      "Epoch 18/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1191 - acc: 0.6168\n",
      "Epoch 19/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0829 - acc: 0.6387\n",
      "Epoch 20/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1371 - acc: 0.6267\n",
      "Epoch 21/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1702 - acc: 0.6287\n",
      "Epoch 22/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1428 - acc: 0.6786\n",
      "Epoch 23/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1318 - acc: 0.6627\n",
      "Epoch 24/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1194 - acc: 0.6068\n",
      "Epoch 25/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1261 - acc: 0.6228\n",
      "Epoch 26/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1006 - acc: 0.6906\n",
      "Epoch 27/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1200 - acc: 0.6487\n",
      "Epoch 28/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0671 - acc: 0.6367\n",
      "Epoch 29/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1284 - acc: 0.6567\n",
      "Epoch 30/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1416 - acc: 0.6627\n",
      "Epoch 31/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0895 - acc: 0.7026\n",
      "Epoch 32/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0660 - acc: 0.7006\n",
      "Epoch 33/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0233 - acc: 0.6946\n",
      "Epoch 34/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0062 - acc: 0.6886\n",
      "Epoch 35/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0201 - acc: 0.6766\n",
      "Epoch 36/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0417 - acc: 0.6966\n",
      "Epoch 37/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0850 - acc: 0.6707\n",
      "Epoch 38/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0994 - acc: 0.6707\n",
      "Epoch 39/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0928 - acc: 0.6786\n",
      "Epoch 40/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0344 - acc: 0.7265\n",
      "Epoch 41/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0269 - acc: 0.6866\n",
      "Epoch 42/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0941 - acc: 0.6747\n",
      "Epoch 43/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.1488 - acc: 0.6667\n",
      "Epoch 44/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0533 - acc: 0.6906\n",
      "Epoch 45/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0335 - acc: 0.6747\n",
      "Epoch 46/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0334 - acc: 0.7026\n",
      "Epoch 47/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0096 - acc: 0.7186\n",
      "Epoch 48/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9983 - acc: 0.6926\n",
      "Epoch 49/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9851 - acc: 0.7206\n",
      "Epoch 50/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9881 - acc: 0.7385\n",
      "Epoch 51/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9711 - acc: 0.6966\n",
      "Epoch 52/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0011 - acc: 0.6926\n",
      "Epoch 53/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9958 - acc: 0.6926\n",
      "Epoch 54/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9931 - acc: 0.7126\n",
      "Epoch 55/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0201 - acc: 0.6946\n",
      "Epoch 56/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9990 - acc: 0.7285\n",
      "Epoch 57/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0031 - acc: 0.6966\n",
      "Epoch 58/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0265 - acc: 0.6946\n",
      "Epoch 59/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0368 - acc: 0.6886\n",
      "Epoch 60/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9865 - acc: 0.7405\n",
      "Epoch 61/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9974 - acc: 0.7405\n",
      "Epoch 62/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9691 - acc: 0.7345\n",
      "Epoch 63/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9558 - acc: 0.7385\n",
      "Epoch 64/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0042 - acc: 0.6906\n",
      "Epoch 65/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0144 - acc: 0.6846\n",
      "Epoch 66/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9767 - acc: 0.7585\n",
      "Epoch 67/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0184 - acc: 0.6886\n",
      "Epoch 68/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9754 - acc: 0.7106\n",
      "Epoch 69/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0295 - acc: 0.7046\n",
      "Epoch 70/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0022 - acc: 0.7226\n",
      "Epoch 71/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 2.0006 - acc: 0.6966\n",
      "Epoch 72/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9939 - acc: 0.7226\n",
      "Epoch 73/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9758 - acc: 0.7365\n",
      "Epoch 74/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9537 - acc: 0.7425\n",
      "Epoch 75/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9243 - acc: 0.7425\n",
      "Epoch 76/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9493 - acc: 0.7126\n",
      "Epoch 77/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9435 - acc: 0.7625\n",
      "Epoch 78/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9494 - acc: 0.7485\n",
      "Epoch 79/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9088 - acc: 0.7884\n",
      "Epoch 80/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8822 - acc: 0.7705\n",
      "Epoch 81/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9118 - acc: 0.7226\n",
      "Epoch 82/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9426 - acc: 0.7186\n",
      "Epoch 83/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9466 - acc: 0.7645\n",
      "Epoch 84/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9008 - acc: 0.7784\n",
      "Epoch 85/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9280 - acc: 0.7605\n",
      "Epoch 86/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9070 - acc: 0.7645\n",
      "Epoch 87/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8817 - acc: 0.7685\n",
      "Epoch 88/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8756 - acc: 0.7884\n",
      "Epoch 89/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8970 - acc: 0.7625\n",
      "Epoch 90/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8885 - acc: 0.7625\n",
      "Epoch 91/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8676 - acc: 0.7745\n",
      "Epoch 92/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8671 - acc: 0.7685\n",
      "Epoch 93/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8866 - acc: 0.7804\n",
      "Epoch 94/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8873 - acc: 0.7545\n",
      "Epoch 95/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8658 - acc: 0.7645\n",
      "Epoch 96/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8064 - acc: 0.7844\n",
      "Epoch 97/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8350 - acc: 0.7844\n",
      "Epoch 98/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8387 - acc: 0.7665\n",
      "Epoch 99/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8760 - acc: 0.7844\n",
      "Epoch 100/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8929 - acc: 0.7745\n",
      "Epoch 101/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.9283 - acc: 0.7884\n",
      "Epoch 102/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8817 - acc: 0.7784\n",
      "Epoch 103/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8729 - acc: 0.7764\n",
      "Epoch 104/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8424 - acc: 0.8084\n",
      "Epoch 105/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8402 - acc: 0.7705\n",
      "Epoch 106/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8483 - acc: 0.7844\n",
      "Epoch 107/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8728 - acc: 0.7824\n",
      "Epoch 108/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8677 - acc: 0.7725\n",
      "Epoch 109/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8400 - acc: 0.7764\n",
      "Epoch 110/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7621 - acc: 0.7984\n",
      "Epoch 111/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7674 - acc: 0.8084\n",
      "Epoch 112/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8036 - acc: 0.7924\n",
      "Epoch 113/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8435 - acc: 0.7864\n",
      "Epoch 114/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8544 - acc: 0.7565\n",
      "Epoch 115/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8563 - acc: 0.7804\n",
      "Epoch 116/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8209 - acc: 0.7904\n",
      "Epoch 117/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8289 - acc: 0.7944\n",
      "Epoch 118/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8174 - acc: 0.7944\n",
      "Epoch 119/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7954 - acc: 0.7944\n",
      "Epoch 120/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8170 - acc: 0.7884\n",
      "Epoch 121/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8090 - acc: 0.8064\n",
      "Epoch 122/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8043 - acc: 0.8104\n",
      "Epoch 123/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7976 - acc: 0.7964\n",
      "Epoch 124/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8005 - acc: 0.7984\n",
      "Epoch 125/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8125 - acc: 0.8084\n",
      "Epoch 126/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7968 - acc: 0.8084\n",
      "Epoch 127/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8015 - acc: 0.7984\n",
      "Epoch 128/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8077 - acc: 0.7964\n",
      "Epoch 129/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8451 - acc: 0.7844\n",
      "Epoch 130/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8425 - acc: 0.7804\n",
      "Epoch 131/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7662 - acc: 0.7864\n",
      "Epoch 132/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7725 - acc: 0.8024\n",
      "Epoch 133/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.7950 - acc: 0.8144\n",
      "Epoch 134/200\n",
      "501/501 [==============================] - 1s 2ms/step - loss: 1.8095 - acc: 0.8084\n",
      "Epoch 135/200\n",
      "128/501 [======>.......................] - ETA: 0s - loss: 1.8556 - acc: 0.8359"
     ]
    }
   ],
   "source": [
    "model.fit(x_combined_train.values, y_combined_train, epochs = 200, batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2944372399838384, 0.8023952102946664]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_combined_test, y_combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.epoch, model.history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of different data sets with one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets and corresponding labels\n",
    "Datasets = [\n",
    "    [x_cnv_processed, 'CNV Only'],\n",
    "    [x_rna_processed, 'RNA Only'],\n",
    "    [x_lnc_processed, 'lnc Only'],\n",
    "    [x_cr, 'CNV and RNA'],\n",
    "    [x_cl, 'CNV and lnc'],\n",
    "    [x_rl, 'RNA and lnc'],\n",
    "    [x_all, 'CNV, RNA and lnc']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV Only [0.6747740771242244, 0.7425149711306224]\n",
      "RNA Only [0.8499456329973872, 0.7245508985605068]\n",
      "lnc Only [1.2996799467566484, 0.598802396280323]\n",
      "CNV and RNA [0.5016457552681426, 0.7964071863425706]\n",
      "CNV and lnc [0.628189865343585, 0.7544910186778999]\n",
      "RNA and lnc [0.7763335169432406, 0.7065868274180475]\n",
      "CNV, RNA and lnc [0.5762685444540606, 0.7544910186778999]\n"
     ]
    }
   ],
   "source": [
    "for df, label in Datasets:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df, y.values.flatten(), test_size = 0.25, random_state = 0)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation = 'tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation = 'tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(x_train.values, y_train, epochs = 150, batch_size = 128, verbose = 0)\n",
    "    print(label, model.evaluate(x_test, y_test, verbose = 0))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
